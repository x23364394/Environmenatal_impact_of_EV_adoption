{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#1:Now we try to upload the json to mongodb\n",
    "cl=MongoClient('mongodb://localhost:27017/')\n",
    "dab=cl['ev_project']\n",
    "coll=dab['ev_registrations']\n",
    "coll.drop()\n",
    "\n",
    "with open('ev_registrations.json','r') as file:\n",
    "    json_da=json.load(file)\n",
    "da=json_da['data']\n",
    "colm=[col['name']for col in json_da['meta']['view']['columns']]\n",
    "data_dt=[dict(zip(colm,recd))for recd in da]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bed3873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in MongoDB: 770809\n"
     ]
    }
   ],
   "source": [
    "#it is also necessary for us to insert it in chunks for better efficiency\n",
    "cz=1000\n",
    "total_rec=len(data_dt)\n",
    "for i in range(0,total_rec,cz):\n",
    "    ck=data_dt[i:i+cz]\n",
    "    coll.insert_many(ck)\n",
    "print(f\"Total in MongoDB: {coll.count_documents({})}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7eb896",
   "metadata": {},
   "source": [
    "We are trying to pre-process the data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8604d008-92e0-4ac0-adef-7c48c16705f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "cl=MongoClient('mongodb://localhost:27017/')\n",
    "dab=cl['ev_project']\n",
    "coll=dab['ev_registrations']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db87126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=datetime(2023,1,1)\n",
    "ed=datetime(2025,6,30)\n",
    "evda=list(coll.find({'Fuel Type':'Electric','Transaction Date':{'$gte':sd.strftime('%Y-%m-%d'),'$lte':ed.strftime('%Y-%m-%d')}}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096eed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8797\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(evda).drop(columns=['_id','sid','id','position','created_at','updated_at','updated_meta','meta','Fiscal Year'],errors='ignore')\n",
    "\n",
    "df['Counts']=pd.to_numeric(df['Counts'],errors='coerce')\n",
    "df=df.drop_duplicates()\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e452377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniq residential county 39\n",
      "unique fuel type 1\n",
      "8448\n"
     ]
    }
   ],
   "source": [
    "print('uniq residential county',df['Residential County'].nunique())\n",
    "print('unique fuel type',df['Fuel Type'].nunique())\n",
    "print(df['Counts'].max())  #we try to see the max value of counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4206699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 rows   Residential County YearMonth Fuel Type  Primary Use Class  Counts\n",
      "0              Adams   2023-01  Electric         Commercial       1\n",
      "1              Adams   2023-01  Electric  Passenger Vehicle       1\n",
      "2              Adams   2023-02  Electric              Truck       1\n",
      "3              Adams   2023-03  Electric  Passenger Vehicle       1\n",
      "4              Adams   2023-04  Electric  Passenger Vehicle       4\n"
     ]
    }
   ],
   "source": [
    "#we try to print only the monthly data instead of daily data\n",
    "df['Transaction Date']=pd.to_datetime(df['Transaction Date'])\n",
    "df['YearMonth']=df['Transaction Date'].dt.to_period('M')\n",
    "df_group=df.groupby(['Residential County','YearMonth','Fuel Type','Primary Use Class'],as_index=False)['Counts'].sum()\n",
    "df_group['Residential County']=df_group['Residential County'].str.strip()\n",
    "\n",
    "print('first 5 rows',df_group.head())\n",
    "df_group.to_csv('ev_cleaned_monthly.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a7427",
   "metadata": {},
   "source": [
    "From here the Dagster pipeline grabs the vehicle dataset from MongoDB and then saves table in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e3600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagster import job, op, In, Out\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf43275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(out=Out(pd.DataFrame))\n",
    "def transform_evdata():\n",
    "    cl=MongoClient('mongodb://localhost:27017/')\n",
    "    dab=cl['ev_project']\n",
    "    coll=dab['ev_registrations']\n",
    "\n",
    "    sd=datetime(2023,1,1)\n",
    "    ed=datetime(2025,12,31)\n",
    "    evda=list(coll.find({'Fuel Type':'Electric','Transaction Date':{'$gte':sd.strftime('%Y-%m-%d'),'$lte':ed.strftime('%Y-%m-%d')}}))\n",
    "\n",
    "    df=pd.DataFrame(evda).drop(columns=['_id','sid','id','position','created_at','updated_at','updated_meta','meta','Fiscal Year'],errors='ignore')\n",
    "    df['Counts']=pd.to_numeric(df['Counts'],errors='coerce')\n",
    "    df=df.drop_duplicates()\n",
    "    print(\"raw data\",len(df))\n",
    "    \n",
    "\n",
    "# we are actually trying to debug the raw data present\n",
    "    df['Transaction Date']=pd.to_datetime(df['Transaction Date'])\n",
    "    df['YearMonth']=df['Transaction Date'].dt.to_period('M')\n",
    "    print(\"Unique YearMonths \\t\", df['YearMonth'].nunique())\n",
    "    df_group=df.groupby(['Residential County','YearMonth','Fuel Type','Primary Use Class'],as_index=False)['Counts'].sum()\n",
    "    df_group['Residential County']=df_group['Residential County'].str.strip()\n",
    "    df_group['YearMonth']=df_group['YearMonth'].astype(str)\n",
    "    \n",
    "    df['Transaction Date']=pd.to_datetime(df['Transaction Date'])\n",
    "    df['YearMonth']=df['Transaction Date'].dt.to_period('M')\n",
    "    print(\"Unique YearMonths \\t\",df['YearMonth'].nunique())\n",
    "    \n",
    "    df_group=df.groupby(['Residential County','YearMonth','Fuel Type','Primary Use Class'],as_index=False)['Counts'].sum()\n",
    "    df_group['Residential County']=df_group['Residential County'].str.strip()\n",
    "    df_group['YearMonth']=df_group['YearMonth'].astype(str)\n",
    "    \n",
    "    \n",
    "# now once debugging is done we try to debug the aggregated data\n",
    "    print(\"\\nAggregated data \\t\")\n",
    "    print(\"Total rows \\t\",len(df_group))\n",
    "    print(\"Unique Residential Counties \\t\",df_group['Residential County'].nunique())\n",
    "    print(\"Unique YearMonths \\t\",df_group['YearMonth'].nunique())\n",
    "    print(\"Unique Primary Use Classes \\t\",df_group['Primary Use Class'].nunique())\n",
    "    print(\"Aggregated Counts summary \\n\",df_group['Counts'].describe())\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3997757",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(ins={\"df\":In(pd.DataFrame)},out=Out(str))\n",
    "def save_to_postgres(df):\n",
    "    try:\n",
    "        engine = create_engine('postgresql://postgres:password@localhost:5432/ev_project_cleaned')\n",
    "        df.to_sql('ev_registrations_cleaned',engine,if_exists='replace',index=False)\n",
    "        print(\"Data saved into the PostgreSQL\")\n",
    "        return \"Saved to PostgreSQL\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to PostgreSQL:{e}\")\n",
    "        return f\"Failed to save:{e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c692d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@job \n",
    "def ev_data_pipeline():\n",
    "    df=transform_evdata()\n",
    "    save_to_postgres(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b09a3",
   "metadata": {},
   "source": [
    "Here we are performing EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Danish Rehman\\anaconda3\\Lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (3.9.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Danish Rehman\\anaconda3\\Lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Danish Rehman\\anaconda3\\Lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (0.13.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (1.4.54)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danish rehman\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas matplotlib seaborn sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d244068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fa7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize']=(12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58070300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danish Rehman\\AppData\\Local\\Temp\\ipykernel_14632\\2679531264.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df=pd.read_sql('SELECT * FROM ev_registrations_cleaned',engine)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in reading from postgres 'Engine' object has no attribute 'cursor'\n",
      "Loaded 4252 rows from CSV\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    engine=create_engine('postgresql://postgres:password@localhost:5432/ev_project_cleaned')\n",
    "    df=pd.read_sql('SELECT * FROM ev_registrations_cleaned',engine)\n",
    "except Exception as e:\n",
    "    print(f\"error in reading from postgres {e}\")\n",
    "    try:\n",
    "        df=pd.read_csv('ev_cleaned_monthly.csv')\n",
    "        print(f\"Loaded {len(df)} rows from CSV\")\n",
    "    except Exception as e:\n",
    "        print(\"There is some error in loading\")\n",
    "        exit(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "089a7c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colomns in th DF ['Residential County', 'YearMonth', 'Fuel Type', 'Primary Use Class', 'Counts']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4252 entries, 0 to 4251\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Residential County  4252 non-null   object\n",
      " 1   YearMonth           4252 non-null   object\n",
      " 2   Fuel Type           4252 non-null   object\n",
      " 3   Primary Use Class   4252 non-null   object\n",
      " 4   Counts              4252 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 166.2+ KB\n",
      "None\n",
      "Residential County    0\n",
      "YearMonth             0\n",
      "Fuel Type             0\n",
      "Primary Use Class     0\n",
      "Counts                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Colomns in th DF\",list(df.columns))\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382a6c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resedntial county 39\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"Resedntial county {df['Residential County'].nunique()}\")\n",
    "except KeyError:\n",
    "    print(\"Residential County column not found\",list(df.columns))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d593b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuel Type 1\n",
      "Primary Use Class 21\n",
      "count    4252.000000\n",
      "mean       86.288570\n",
      "std       593.386344\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%        12.000000\n",
      "max      9369.000000\n",
      "Name: Counts, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fuel Type {df['Fuel Type'].nunique()}\")\n",
    "print(f\"Primary Use Class {df['Primary Use Class'].nunique()}\")\n",
    "print(df['Counts'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31356b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
